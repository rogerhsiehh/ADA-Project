{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092fa3d7-662c-4352-bb0b-be1ec8d4d624",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce28c817-0e3d-4b48-b319-adea82ebefdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Excel file: CarDD_release/CarDD_COCO/annotations/image_info.xlsx\n",
      "Excel File Preview:\n",
      "   id   file_name  width  height  file_size (KB)  #instances  #categories  \\\n",
      "0   1  000001.jpg   1000     750            1114           2            2   \n",
      "1   2  000002.jpg   1000     667             637           1            1   \n",
      "2   3  000003.jpg   1000     667             966           1            1   \n",
      "3   4  000004.jpg   1000     667             806           1            1   \n",
      "4   5  000005.jpg   1000     667             959           1            1   \n",
      "\n",
      "  shooting angle complete or partial   color  \n",
      "0           side              partial    red  \n",
      "1           side              partial  white  \n",
      "2           side              partial  white  \n",
      "3           side              partial   gray  \n",
      "4           side              partial   gray  \n",
      "\n",
      "Loading COCO JSON file: CarDD_release/CarDD_COCO/annotations/instances_train2017.json\n",
      "COCO JSON Keys:\n",
      "['licenses', 'info', 'categories', 'images', 'annotations']\n",
      "Example data (annotations):\n",
      "[{'id': 1, 'image_id': 1, 'category_id': 2, 'segmentation': [[233.35, 46.65, 217.25, 58.24, 210.82, 65.97, 204.38, 78.2, 197.3, 93.0, 192.15, 104.59, 187.0, 112.96, 180.56, 123.91, 174.12, 135.49, 169.61, 144.51, 167.04, 154.16, 167.04, 165.11, 175.41, 170.9, 185.71, 171.55, 196.01, 167.68, 205.02, 161.24, 214.03, 154.81, 224.33, 148.37, 233.99, 141.93, 244.29, 134.21, 256.52, 128.41, 267.47, 125.19, 277.77, 122.62, 288.71, 119.4, 298.37, 116.82, 310.6, 113.61, 322.83, 109.1, 333.13, 105.88, 344.08, 103.95, 355.02, 101.37, 366.61, 97.51, 369.83, 87.21, 364.68, 78.84, 352.45, 69.18, 341.5, 61.46, 331.2, 55.02, 314.46, 48.58, 302.23, 44.72, 291.93, 42.15, 276.48, 40.21, 266.18, 40.21, 254.59, 40.21]], 'area': 13584.0, 'bbox': [167.04, 40.21, 202.79, 131.34], 'iscrowd': 0, 'attributes': {'occluded': False}}, {'id': 2, 'image_id': 1, 'category_id': 6, 'segmentation': [[348.93, 137.7, 336.68, 141.53, 323.67, 146.12, 312.19, 151.48, 299.95, 158.37, 289.23, 164.49, 279.29, 171.38, 270.1, 179.03, 260.92, 187.45, 251.73, 195.1, 243.32, 205.05, 235.66, 214.23, 228.01, 223.42, 217.3, 237.96, 209.64, 247.14, 202.76, 257.09, 196.63, 267.04, 190.51, 278.52, 184.39, 288.47, 178.27, 298.42, 171.38, 310.66, 166.79, 322.91, 163.72, 335.15, 162.96, 346.63, 162.96, 359.64, 160.66, 371.12, 160.66, 384.9, 160.66, 397.91, 160.66, 410.92, 162.19, 422.4, 166.02, 439.23, 168.32, 450.71, 171.38, 462.96, 175.97, 473.67, 181.33, 484.39, 188.98, 494.34, 195.87, 504.29, 202.76, 514.23, 208.88, 524.18, 215.77, 534.13, 224.95, 542.55, 236.43, 548.67, 245.61, 557.09, 249.44, 569.34, 253.27, 580.82, 259.39, 590.77, 265.51, 600.71, 277.76, 606.07, 290.77, 607.6, 302.24, 609.9, 313.72, 611.43, 325.2, 613.72, 336.68, 616.79, 348.16, 620.61, 358.88, 625.2, 371.89, 629.03, 383.37, 633.62, 394.85, 636.68, 407.86, 640.51, 419.34, 643.57, 432.35, 645.87, 445.36, 648.93, 456.84, 651.99, 469.08, 655.05, 481.33, 658.11, 492.81, 659.64, 504.29, 660.41, 518.06, 660.41, 531.07, 660.41, 542.55, 661.17, 554.03, 661.94, 568.57, 663.47, 583.88, 663.47, 596.89, 661.94, 612.96, 658.11, 625.2, 655.05, 637.45, 653.52, 651.22, 651.99, 662.7, 650.46, 674.95, 648.16, 686.43, 645.87, 697.91, 645.1, 709.39, 644.34, 721.63, 642.04, 735.41, 635.92, 747.65, 629.8, 757.6, 622.91, 767.55, 616.79, 777.5, 609.9, 788.21, 599.95, 794.34, 590.0, 800.46, 579.29, 805.82, 567.81, 811.94, 556.33, 818.06, 545.61, 824.95, 534.9, 832.6, 524.18, 837.96, 513.47, 840.26, 500.46, 842.55, 487.45, 844.85, 473.67, 844.85, 460.66, 844.85, 446.89, 841.79, 431.58, 840.26, 420.1, 839.49, 406.33, 837.19, 394.85, 835.66, 383.37, 834.13, 371.12, 831.07, 358.88, 826.48, 346.63, 823.42, 335.15, 818.83, 321.38, 813.47, 306.84, 808.88, 296.12, 803.52, 284.64, 796.63, 273.93, 787.45, 264.74, 779.03, 256.33, 771.38, 245.61, 761.43, 233.37, 750.71, 224.18, 738.47, 213.47, 730.82, 203.52, 723.16, 194.34, 712.45, 185.92, 699.44, 178.27, 689.49, 169.85, 678.78, 163.72, 658.88, 150.71, 635.92, 146.12, 619.08, 141.53, 597.65, 132.35, 585.41, 127.76, 568.57, 123.93, 556.33, 121.63, 541.02, 118.57, 528.01, 116.28, 514.23, 113.98, 498.16, 113.21, 485.92, 112.45, 469.85, 112.45, 452.24, 112.45, 436.17, 112.45, 420.1, 113.21, 407.86, 117.04, 392.55, 123.16, 380.31, 125.46, 369.59, 131.58]], 'area': 298742.0, 'bbox': [160.66, 112.45, 684.19, 551.02], 'iscrowd': 0, 'attributes': {'occluded': False}}]\n",
      "\n",
      "Loading COCO JSON file: CarDD_release/CarDD_COCO/annotations/instances_val2017.json\n",
      "COCO JSON Keys:\n",
      "['licenses', 'info', 'categories', 'images', 'annotations']\n",
      "Example data (annotations):\n",
      "[{'id': 1, 'image_id': 13, 'category_id': 3, 'segmentation': [[454.28, 238.69, 473.82, 254.41, 522.26, 257.81, 506.96, 235.72, 489.54, 227.22, 472.12, 227.65, 459.37, 231.47]], 'area': 1332.0, 'bbox': [454.28, 227.22, 67.98, 30.59], 'iscrowd': 0, 'attributes': {'occluded': False}}, {'id': 2, 'image_id': 13, 'category_id': 4, 'segmentation': [[477.42, 67.25, 475.02, 69.1, 471.33, 72.06, 468.92, 73.9, 466.71, 75.75, 464.12, 77.6, 461.35, 79.45, 458.21, 81.66, 455.99, 83.7, 453.59, 85.73, 451.37, 87.76, 448.23, 90.16, 445.83, 92.01, 443.06, 94.04, 440.29, 95.7, 437.33, 97.55, 434.74, 99.4, 431.6, 101.8, 429.75, 104.2, 428.09, 106.79, 425.69, 109.56, 423.47, 111.59, 421.07, 113.44, 418.48, 115.47, 415.53, 118.25, 413.13, 120.09, 410.17, 122.68, 407.4, 125.45, 404.63, 127.85, 402.59, 129.89, 401.49, 132.47, 404.63, 133.4, 408.88, 133.58, 411.65, 133.4, 414.97, 133.21, 418.3, 133.21, 422.18, 133.21, 425.13, 133.03, 428.65, 132.66, 431.6, 132.47, 434.74, 132.47, 438.44, 132.29, 441.39, 132.29, 444.35, 131.92, 447.12, 131.73, 450.08, 131.36, 453.59, 131.36, 456.54, 131.36, 460.61, 131.36, 464.67, 131.36, 467.63, 131.36, 471.51, 131.36, 475.39, 131.36, 479.64, 131.36, 483.7, 131.36, 486.66, 132.1, 489.25, 133.58, 492.2, 134.87, 495.16, 135.61, 498.3, 136.54, 501.07, 137.09, 504.03, 138.02, 507.91, 138.57, 510.86, 138.75, 514.56, 138.94, 517.33, 139.31, 520.84, 139.49, 523.8, 139.86, 527.86, 140.42, 531.74, 141.16, 535.62, 141.53, 538.39, 141.71, 541.35, 142.08, 544.49, 142.45, 547.45, 143.0, 550.22, 143.37, 552.99, 143.93, 556.32, 144.3, 559.09, 144.85, 561.86, 145.41, 565.74, 145.96, 569.06, 146.51, 572.21, 147.07, 575.9, 147.62, 579.04, 147.81, 582.0, 147.81, 584.21, 145.96, 586.62, 143.74, 589.57, 140.97, 592.16, 137.83, 594.01, 135.24, 595.85, 131.92, 597.7, 128.41, 599.37, 125.82, 601.21, 122.68, 603.61, 119.72, 605.83, 116.77, 608.23, 114.55, 611.01, 111.96, 612.85, 109.56, 614.7, 106.98, 616.36, 103.65, 617.84, 100.88, 619.87, 97.74, 621.72, 95.34, 623.75, 93.3, 626.34, 90.72, 628.56, 88.87, 630.22, 86.47, 633.18, 82.96, 635.58, 79.63, 638.35, 75.94, 640.2, 73.16, 642.23, 70.39, 645.0, 66.88, 647.96, 63.56, 649.81, 61.34, 652.02, 57.83, 654.24, 54.87, 656.46, 51.36, 658.12, 48.04, 659.6, 45.08, 659.41, 42.31, 655.35, 40.83, 652.58, 40.28, 648.14, 39.72, 642.6, 39.54, 636.5, 39.54, 630.77, 39.54, 623.75, 39.17, 618.4, 39.17, 613.04, 39.54, 606.02, 40.28, 599.37, 40.83, 592.53, 41.38, 585.51, 41.94, 577.75, 43.05, 572.39, 43.6, 563.34, 44.16, 555.21, 44.9, 547.45, 45.82, 541.53, 46.74, 528.23, 49.33, 523.61, 50.25, 518.44, 51.36, 512.53, 52.66, 505.14, 54.87, 498.49, 56.9, 490.91, 59.86, 486.11, 61.71, 482.6, 63.0]], 'area': 16512.0, 'bbox': [401.49, 39.17, 258.11, 108.64], 'iscrowd': 0, 'attributes': {'occluded': False}}]\n",
      "\n",
      "Loading COCO JSON file: CarDD_release/CarDD_COCO/annotations/instances_test2017.json\n",
      "COCO JSON Keys:\n",
      "['licenses', 'info', 'categories', 'images', 'annotations']\n",
      "Example data (annotations):\n",
      "[{'id': 1, 'image_id': 12, 'category_id': 6, 'segmentation': [[148.33, 227.67, 131.8, 229.88, 115.27, 236.49, 100.94, 248.61, 88.82, 260.73, 73.39, 275.06, 62.37, 289.39, 54.65, 305.92, 46.94, 322.45, 40.33, 338.98, 37.02, 356.61, 34.82, 375.35, 32.61, 394.08, 32.61, 415.02, 32.61, 433.76, 35.92, 452.49, 40.33, 470.12, 45.84, 486.65, 54.65, 500.98, 64.57, 515.31, 78.9, 527.43, 94.33, 535.14, 110.86, 537.35, 129.59, 539.55, 147.22, 542.86, 163.76, 546.16, 182.49, 549.47, 200.12, 550.57, 219.96, 551.67, 237.59, 553.88, 255.22, 553.88, 273.96, 553.88, 307.02, 543.96, 321.35, 531.84, 331.27, 515.31, 341.18, 499.88, 346.69, 483.35, 352.2, 466.82, 355.51, 449.18, 358.82, 430.45, 362.12, 411.71, 364.33, 395.18, 362.12, 377.55, 346.69, 369.84, 330.16, 368.73, 315.84, 356.61, 307.02, 336.78, 300.41, 319.14, 294.9, 302.61, 287.18, 283.88, 280.57, 268.45, 270.65, 250.82, 257.43, 237.59, 242.0, 227.67, 225.47, 222.16, 208.94, 221.06, 191.31, 221.06, 171.47, 221.06]], 'area': 85783.0, 'bbox': [32.61, 221.06, 331.72, 332.82], 'iscrowd': 0, 'attributes': {'occluded': False}}, {'id': 2, 'image_id': 12, 'category_id': 6, 'segmentation': [[858.04, 372.04, 860.24, 388.57, 861.35, 405.1, 861.35, 422.73, 858.04, 440.37, 851.43, 458.0, 845.92, 476.73, 838.2, 492.16, 828.29, 506.49, 815.06, 517.51, 796.33, 518.61, 778.69, 517.51, 764.37, 507.59, 745.63, 503.18, 728.0, 502.08, 711.47, 496.57, 699.35, 483.35, 687.22, 470.12, 692.73, 450.29, 703.76, 435.96, 708.16, 418.33, 707.06, 398.49, 707.06, 380.86, 721.39, 369.84, 740.12, 369.84, 757.76, 368.73, 776.49, 368.73, 795.22, 368.73, 813.96, 368.73, 830.49, 367.63]], 'area': 20953.0, 'bbox': [687.22, 367.63, 174.13, 150.98], 'iscrowd': 0, 'attributes': {'occluded': False}}]\n",
      "\n",
      "Training Dataset: 2816 images, 6211 annotations\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 1. Load and Explore the Excel File\n",
    "def load_excel(file_path):\n",
    "    \"\"\"Load an Excel file and display its contents.\"\"\"\n",
    "    print(f\"Loading Excel file: {file_path}\")\n",
    "    try:\n",
    "        data = pd.read_excel(file_path)\n",
    "        print(\"Excel File Preview:\")\n",
    "        print(data.head())\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Excel file: {e}\")\n",
    "        return None\n",
    "\n",
    "# 2. Load and Explore COCO JSON Files\n",
    "def load_coco_json(file_path):\n",
    "    \"\"\"Load a COCO JSON file and display its structure.\"\"\"\n",
    "    print(f\"\\nLoading COCO JSON file: {file_path}\")\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        print(\"COCO JSON Keys:\")\n",
    "        print(list(data.keys()))\n",
    "        print(\"Example data (annotations):\")\n",
    "        if \"annotations\" in data:\n",
    "            print(data[\"annotations\"][:2])  # Show a preview of annotations\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading JSON file: {e}\")\n",
    "        return None\n",
    "\n",
    "# 3. Paths to Dataset Files\n",
    "excel_file = \"CarDD_release/CarDD_COCO/annotations/image_info.xlsx\"  # Update with the correct path if necessaryy\n",
    "coco_train_json = \"CarDD_release/CarDD_COCO/annotations/instances_train2017.json\"\n",
    "coco_val_json = \"CarDD_release/CarDD_COCO/annotations/instances_val2017.json\"\n",
    "coco_test_json = \"CarDD_release/CarDD_COCO/annotations/instances_test2017.json\"\n",
    "\n",
    "# 4. Run the Functions to Explore the Dataset\n",
    "# Uncomment the following lines if files are in the same directory\n",
    "excel_data = load_excel(excel_file)\n",
    "train_data = load_coco_json(coco_train_json)\n",
    "val_data = load_coco_json(coco_val_json)\n",
    "test_data = load_coco_json(coco_test_json)\n",
    "\n",
    "# 5. Example of Inspecting Data\n",
    "# Check number of images and annotations in the train set\n",
    "if train_data:\n",
    "    num_images = len(train_data.get(\"images\", []))\n",
    "    num_annotations = len(train_data.get(\"annotations\", []))\n",
    "    print(f\"\\nTraining Dataset: {num_images} images, {num_annotations} annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed06e2-f45b-4d5c-823d-60e41f67a969",
   "metadata": {},
   "source": [
    "# Generating Multi-Label Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d32c4d-ced8-44bf-9b15-3313dbaaf785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of categories: 6\n",
      "\n",
      "Processing train dataset...\n",
      "\n",
      "Generating multi-label vectors for images...\n",
      "\n",
      "Train Multi-Label DataFrame Preview:\n",
      "   image_id  multi_label_vector\n",
      "0         1  [0, 1, 0, 0, 0, 1]\n",
      "1         2  [0, 0, 0, 0, 0, 1]\n",
      "2         3  [0, 0, 0, 0, 0, 1]\n",
      "3         4  [0, 0, 0, 0, 0, 1]\n",
      "4         5  [0, 0, 0, 0, 0, 1]\n",
      "\n",
      "Multi-label vectors for train saved to 'multi_label_vectors_train.csv'\n",
      "\n",
      "Processing val dataset...\n",
      "\n",
      "Generating multi-label vectors for images...\n",
      "\n",
      "Val Multi-Label DataFrame Preview:\n",
      "   image_id  multi_label_vector\n",
      "0        13  [0, 0, 1, 1, 0, 1]\n",
      "1        16  [1, 1, 0, 0, 0, 0]\n",
      "2        17  [0, 1, 0, 0, 0, 0]\n",
      "3        24  [0, 1, 0, 0, 0, 0]\n",
      "4        25  [0, 1, 0, 0, 0, 0]\n",
      "\n",
      "Multi-label vectors for val saved to 'multi_label_vectors_val.csv'\n",
      "\n",
      "Processing test dataset...\n",
      "\n",
      "Generating multi-label vectors for images...\n",
      "\n",
      "Test Multi-Label DataFrame Preview:\n",
      "   image_id  multi_label_vector\n",
      "0        12  [0, 0, 0, 0, 0, 1]\n",
      "1        15  [0, 1, 0, 0, 0, 0]\n",
      "2        23  [1, 1, 0, 0, 0, 0]\n",
      "3        33  [1, 0, 0, 0, 0, 0]\n",
      "4        40  [0, 1, 0, 0, 1, 0]\n",
      "\n",
      "Multi-label vectors for test saved to 'multi_label_vectors_test.csv'\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# Step 6: Generate Multi-Label Vectors\n",
    "def generate_multi_label_vectors(data, num_categories):\n",
    "    \"\"\"Generate multi-label vectors for images based on COCO annotations.\"\"\"\n",
    "    print(\"\\nGenerating multi-label vectors for images...\")\n",
    "\n",
    "    # Map image_id to its category_ids\n",
    "    image_to_categories = defaultdict(set)\n",
    "    for ann in data[\"annotations\"]:\n",
    "        image_to_categories[ann[\"image_id\"]].add(ann[\"category_id\"])\n",
    "\n",
    "    # Create multi-label vectors\n",
    "    image_multi_labels = []\n",
    "    for image_id, categories_present in image_to_categories.items():\n",
    "        multi_label_vector = [0] * num_categories  # Initialize all labels to 0\n",
    "        for category in categories_present:\n",
    "            multi_label_vector[category - 1] = 1  # Assuming category IDs are 1-indexed\n",
    "        image_multi_labels.append({\"image_id\": image_id, \"multi_label_vector\": multi_label_vector})\n",
    "\n",
    "    # Convert to a DataFrame for easy exploration\n",
    "    df = pd.DataFrame(image_multi_labels)\n",
    "    return df\n",
    "\n",
    "def process_dataset(data, split_name, num_categories):\n",
    "    \"\"\"Process a dataset and save multi-label vectors for a specific split.\"\"\"\n",
    "    print(f\"\\nProcessing {split_name} dataset...\")\n",
    "    if data:\n",
    "        # Generate the multi-label vectors\n",
    "        multi_label_df = generate_multi_label_vectors(data, num_categories)\n",
    "        \n",
    "        # Display the first few rows\n",
    "        print(f\"\\n{split_name.capitalize()} Multi-Label DataFrame Preview:\")\n",
    "        print(multi_label_df.head())\n",
    "        \n",
    "        # Save the multi-label vectors to a CSV file\n",
    "        output_file = f\"multi_label_vectors_{split_name}.csv\"\n",
    "        multi_label_df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nMulti-label vectors for {split_name} saved to '{output_file}'\")\n",
    "\n",
    "# Get the number of categories from the train dataset (categories are consistent across splits)\n",
    "if train_data:\n",
    "    categories = train_data.get(\"categories\", [])\n",
    "    num_categories = len(categories)\n",
    "    print(f\"\\nNumber of categories: {num_categories}\")\n",
    "\n",
    "    # Process train, validation, and test datasets\n",
    "    process_dataset(train_data, \"train\", num_categories)\n",
    "    process_dataset(val_data, \"val\", num_categories)\n",
    "    process_dataset(test_data, \"test\", num_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e39d5bf-5c67-4fe2-bde2-084acb71cf1a",
   "metadata": {},
   "source": [
    "# Label Mapping\n",
    "\n",
    "The following table describes the mapping of numerical labels to their respective descriptions:\n",
    "\n",
    "| Label Number | Description        |\n",
    "|--------------|--------------------|\n",
    "| 1            | Dent              |\n",
    "| 2            | Scratch           |\n",
    "| 3            | Crack             |\n",
    "| 4            | Glass Shatter     |\n",
    "| 5            | Lamp Broken       |\n",
    "| 6            | Tire Flat         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c723325e-d47d-4b23-9521-90c801552d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
